Defining Software
A textbook description of software might take the following form:   Software is: (1) instructions (computer programs) that when executed provide desired   features, function, and performance; (2) data structures that enable the programs to adequately manipulate information, and (3) descriptive information in both hard copy and   virtual forms that describes the operation and use of the programs. But a more formal definition probably won’t measurably improve your understanding. Software is developed or engineered; it is not manufactured in the classical sense. In both   activities, high quality is achieved through good design, but the manufacturing phase for hardware can introduce quality problems that are nonexistent   pre75977_ch01.qxd  11/27/08  3:11 PM  Page 4   (or easily corrected) for software. Both activities are dependent on people,   but the relationship between people applied and work accomplished is   entirely different (see Chapter 24). Software doesn’t “wear out.”   Figure 1.1 depicts failure rate as a function of time for hardware. The relationship, often called the “bathtub curve,” indicates that hardware exhibits   relatively high failure rates early in its life (these failures are often attributable to design or manufacturing defects); defects are corrected and the failure   rate drops to a steady-state level (hopefully, quite low) for some period of   time. In theory, therefore, the failure rate curve for software   should take the form of the “idealized curve” shown in Figure 1.2. However, these are corrected and the curve flattens as shown. However, the implication is clear—software doesn’t wear out. pre75977_ch01.qxd  11/27/08  3:11 PM  Page 5   This seeming contradiction can best be explained by considering the   actual curve in Figure 1.2. During its life,2 software will undergo change. As   changes are made, it is likely that errors will be introduced, causing the   failure rate curve to spike as shown in the “actual curve” (Figure 1.2). Before   the curve can return to the original steady-state failure rate, another change   is requested, causing the curve to spike again. Slowly, the minimum failure   rate level begins to rise—the software is deteriorating due to change. Another aspect of wear illustrates the difference between hardware and   software. Every software failure indicates an   error in design or in the process through which design was translated into   machine executable code. Therefore, the software maintenance tasks that   accommodate requests for change involve considerably more complexity   than hardware maintenance. Although the industry is moving toward component-based construction, most   software continues to be custom built. As an engineering discipline evolves, a collection of standard design components is created. In the hardware world, component reuse is a natural part of   the engineering process. In the software world, it is something that has only   begun to be achieved on a broad scale. Modern reusable components encapsulate both data and the processing that is applied to the data, enabling the   software engineer to create new applications from reusable parts.3 For example, today’s interactive user interfaces are built with reusable components   that enable the creation of graphics windows, pull-down menus, and a wide   variety of interaction mechanisms. The data structures and processing detail   required to build the interface are contained within a library of reusable   components for interface construction.
 
Software Application Domains
In either case, the systems software area is characterized by heavy interaction   with computer hardware; heavy usage by multiple users; concurrent operation that requires scheduling, resource sharing, and sophisticated process   management; complex data structures; and multiple external interfaces. Application software—stand-alone programs that solve a specific business   need. Applications in this area process business or technical data in a way   that facilitates business operations or management/technical decision making. In addition to conventional data processing applications, application   software is used to control business functions in real time (e.g., point-of-sale   transaction processing, real-time manufacturing process control). Engineering/scientific software—has been characterized by “number   crunching” algorithms. Applications range from astronomy to volcanology,   from automotive stress analysis to space shuttle orbital dynamics, and   from molecular biology to automated manufacturing. Computer-aided design, system simulation, and other interactive applications have begun to take on real-time and   even system software characteristics. Embedded software—resides within a product or system and is used to   implement and control features and functions for the end user and for the   system itself. Embedded software can perform limited and esoteric functions   (e.g., key pad control for a microwave oven) or provide significant function   and control capability (e.g., digital functions in an automobile such as fuel   control, dashboard displays, and braking systems). Product-line software can focus on a limited and   esoteric marketplace (e.g., inventory control products) or address mass   consumer markets (e.g., word processing, spreadsheets, computer graphics,   multimedia, entertainment, database management, and personal and   business financial applications). In their simplest form, WebApps can   be little more than a set of linked hypertext files that present information   using text and limited graphics. Applications within this area include robotics, expert systems,   pattern recognition (image and voice), artificial neural networks, theorem   proving, and game playing. In some cases, new systems are being built, but in   many others, existing applications are being corrected, adapted, and enhanced. Hopefully, the legacy to be left behind by this generation will   ease the burden of future software engineers. And yet, new challenges (Chapter 31)   have appeared on the horizon:   Open-world computing—the rapid growth of wireless networking may   soon lead to true pervasive, distributed computing. pre75977_ch01.qxd  11/27/08  3:11 PM  Page 8   Netsourcing—the World Wide Web is rapidly becoming a computing engine   as well as a content provider. Open source—a growing trend that results in distribution of source code for   systems applications (e.g., operating systems, database, and development environments) so that many people can contribute to its development.
 
SOFTWARE ENGINEERING
It follows that a concerted effort should be made to understand the   problem before a software solution is developed. • The information technology requirements demanded by individuals, businesses, and governments grow increasing complex with each passing year. Large teams of people now create computer programs that were once built   by a single individual. It   follows that design becomes a pivotal activity. If the software fails, people and major enterprises can experience   anything from minor inconvenience to catastrophic failures. It follows that   software should exhibit high quality. • As the perceived value of a specific application grows, the likelihood is that   its user base and longevity will also grow. As its user base and time-in-use   pre75977_ch01.qxd  11/27/08  3:11 PM  Page 12   increase, demands for adaptation and enhancement will also grow. You will be tempted to add to this definition.9 It says little about the technical aspects of software quality; it does not directly address the need for customer satisfaction or timely product delivery; it omits mention of the importance of measurement   and metrics; it does not state the importance of an effective process. And yet, Bauer’s   definition provides us with a baseline. We need discipline, but we also need   adaptability and agility. Referring to Figure 1.3, any engineering approach (including software engineering) must rest on an organizational commitment to quality. The bedrock that supports software engineering is a quality focus. The foundation for software engineering is the process layer. Process defines a framework   pre75977_ch01.qxd  11/27/08  3:11 PM  Page 13   that must be established for effective delivery of software engineering technology. The software process forms the basis for management control of software projects   and establishes the context in which technical methods are applied, work products   (models, documents, data, reports, forms, etc.) are produced, milestones are established, quality is ensured, and change is properly managed. Software engineering methods provide the technical how-to’s for building software. Methods encompass a broad array of tasks that include communication,   requirements analysis, design modeling, program construction, testing, and support. Software engineering tools provide automated or semiautomated support for the   process and the methods. When tools are integrated so that information created by   one tool can be used by another, a system for the support of software development,   called computer-aided software engineering, is established.
 
THE SOFTWARE PROCESS
An activity strives to achieve a broad objective   (e.g., communication with stakeholders) and is applied regardless of the application   domain, size of the project, complexity of the effort, or degree of rigor with which   software engineering is to be applied. An action (e.g., architectural design) encompasses a set of tasks that produce a major work product (e.g., an architectural design   model). A task focuses on a small, but well-defined objective (e.g., conducting a unit   test) that produces a tangible outcome. In the context of software engineering, a process is not a rigid prescription for how   to build computer software. Rather, it is an adaptable approach that enables the people doing the work (the software team) to pick and choose the appropriate set of   work actions and tasks. The intent is always to deliver software in a timely manner   and with sufficient quality to satisfy those who have sponsored its creation and those   who will use it. pre75977_ch01.qxd  11/27/08  3:11 PM  Page 14   A process framework establishes the foundation for a complete software engineering process by identifying a small number of framework activities that are applicable to all software projects, regardless of their size or complexity. Any complicated journey can be simplified if a map exists. A   software project is a complicated journey, and the planning activity creates a   “map” that helps guide the team as it makes the journey. The map—called a   software project plan—defines the software engineering work by describing   the technical tasks to be conducted, the risks that are likely, the resources   that will be required, the work products to be produced, and a work   schedule. Whether you’re a landscaper, a bridge builder, an aeronautical   engineer, a carpenter, or an architect, you work with models every day. You   create a “sketch” of the thing so that you’ll understand the big picture—what   it will look like architecturally, how the constituent parts fit together, and   many other characteristics. If required, you refine the sketch into greater and   greater detail in an effort to better understand the problem and how you’re   going to solve it. This activity combines code generation (either manual or   automated) and the testing that is required to uncover errors in the code. The software (as a complete entity or as a partially completed increment) is delivered to the customer who evaluates the delivered   product and provides feedback based on the evaluation. That is, communication, planning, modeling, construction,   and deployment are applied repeatedly through a number of project iterations. In general, umbrella activities are applied throughout a software project and help a software team manage and control progress, quality,   change, and risk. Typical umbrella activities include:   Software project tracking and control—allows the software team to   assess progress against the project plan and take any necessary action to   maintain the schedule. Software quality assurance—defines and conducts the activities required   to ensure software quality. Therefore, a process adopted for one project might be significantly   different than a process adopted for another project. Among the differences are   • Overall flow of activities, actions, and tasks and the interdependencies   among them   • Degree to which actions and tasks are defined within each framework activity   • Degree to which work products are identified and required   pre75977_ch01.qxd  11/27/08  3:11 PM  Page 16   • Manner in which quality assurance activities are applied   • Manner in which project tracking and control activities are applied   • Overall degree of detail and rigor with which the process is described   • Degree to which the customer and other stakeholders are involved with the   project   • Level of autonomy given to the software team   • Degree to which team organization and roles are prescribed   In Part 1 of this book, I’ll examine software process in considerable detail. Prescriptive   process models (Chapter 2) stress detailed definition, identification, and application   of process activities and tasks. Their intent is to improve system quality, make projects more manageable, make delivery dates and costs more predictable, and guide   teams of software engineers as they perform the work required to build a system. If   prescriptive models are applied dogmatically and without adaptation, they can increase the level of bureaucracy associated with building computer-based systems   and inadvertently create difficulty for all stakeholders. Agile process models (Chapter 3) emphasize project “agility” and follow a set of principles that lead to a more informal (but, proponents argue, no less effective) approach   to software process. These process models are generally characterized as “agile” because they emphasize maneuverability and adaptability.
 
